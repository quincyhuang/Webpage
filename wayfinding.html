<!doctype html>
<html><!-- InstanceBegin template="/Templates/GeneralPage.dwt" codeOutsideHTMLIsLocked="false" -->
<head>
<meta charset="UTF-8" >
<!-- InstanceBeginEditable name="doctitle" --><title>Haikun Huang</title><!-- InstanceEndEditable -->
<!-- InstanceBeginEditable name="head" --><link href="Templates/style.css" rel="stylesheet" type="text/css"><!-- InstanceEndEditable -->

<!--The following script tag downloads a font from the Adobe Edge Web Fonts server for use within the web page. We recommend that you do not modify it.-->
<script>var __adobewebfontsappname__="dreamweaver"</script>
<script src="http://use.edgefonts.net/bilbo:n4:default.js" type="text/javascript"></script>
</head>

<body>
<header>
  <div class="titlename"><strong>Haikun (Quincy) Huang</strong></div>
  <div class="body-header-div">
	  <a href="index.html" class="nav">Home</a>&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="publications.html" class="nav">Publications</a>&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="about.html" class="nav">Team</a>&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href ="./CV/Haikun_cv_one_page.pdf" class="nav" target="new">CV</a>&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://scholar.google.com/citations?view_op=search_authors&mauthors=Haikun+Huang&hl=en&oi=ao" class="nav" target="new">Google Scholar</a></div>
</header>
<main> <!-- InstanceBeginEditable name="EditRegion Main" -->  <h1><em>Automatic Optimization of Wayfinding Design</em></h1>  <!--</div>-->  <div class="div-project-cell"><img src="thumbnails/wayfinding.png" width="300" class="floating-image-right"/>    <!--    <p class="project-award"><a href="https://innovate.ieee.org/innovation-spotlight/vr-games-exercise-intensity-level-design-plug-in/" class="project-award" target="new"><img src="icon/Project-Award.png" height="13" class="floating-image-intext"/>Featured on IEEE Xplore Innovation Spotlight</a></p>-->    <p class="project-author"><img src="icon/Project-Authors.png" height=17 class="floating-image-intext"/><strong>Haikun Huang</strong>, Ni-Ching Lin, Lorenzo Barrett, Darian Springer, Hsueh-Cheng Wang, Marc Pomplun, Lap-Fai Yu</p>    <!--    <p class="project-author-minor">&nbsp;&nbsp;*Equal contributors</p>-->    <p class="project-keyword"><img src="icon/Project-Keyword.png" height="20" class="floating-image-intext"/>Wayfinding | Navigation | Procedural Modeling | Level Design | Spatial Orientation</p>    <p class="project-status"><img src="icon/Project-Pin.png" height=" 17" class=floating-image-intext/>IEEE Transactions on Visualization and Computer Graphics (TVCG), 2017</p>    <div class="project-description"><img src="icon/Project-Flag.png" height=" 18" class=floating-image-intext/>An automatic tool to help wayfinding designers create better wayfinding designs for architectural spaces, and to help level designers create better game levels.</div>    </br>    <div class="project-description"><img src="icon/Project-Patent.png" height=" 15" class=floating-image-intext/><strong>Patent:</br>      <em>Human Vision-Empowered 3D Scene Analysis Tools</em></strong></br>      <strong>Haikun Huang</strong>, Lap-Fai Yu</br>      US patent application no. 16/598, 718</div>    <div class="project-tool"><a href="paper/wayfinding_main.pdf" class="project-tool" target="new"><img src="icon/Project-Paper.png" height="20" class="floating-image-intext"/>Paper</a> <a href="paper/wayfinding_supp.pdf" class="project-tool" target="new"><img src="icon/Project-Supp.png" height="18" class="floating-image-intext"/>Supplementary Paper</a> <a href="bibtex.txt" class="project-tool" target=new><img src="icon/Project-Bibtex.png" height="20" class="floating-image-intext"/>Bibtex</a> </div>  </div>  <iframe width="966" height="543" src="https://www.youtube.com/embed/gKWTial7cKg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>  </div>  <div class="div-h1">    <h1>Abstract</h1>  </div>  <div class="div-project-cell">    <p class="list">Wayfinding signs play an important role in guiding users to navigate in a virtual environment and in helping pedestrians to find their ways in a real-world architectural site. Conventionally, the wayfinding design of a virtual environment is created manually, so as the wayfinding design of a real-world architectural site. The many possible navigation scenarios, as well as the interplay between signs and human navigation, can make the manual design process overwhelming and non-trivial. As a result, creating a wayfinding design for a typical layout can take months to several years. In this paper, we introduce the Way to Go! approach for automatically generating a wayfinding design for a given layout. The designer simply has to specify some navigation scenarios; our approach will automatically generate an optimized wayfinding design with signs properly placed considering human agents’ visibility and the possibility of making mistakes during a navigation. We demonstrate the effectiveness of our approach in generating wayfinding designs for different layouts such as a train station, a downtown and a canyon. We evaluate our results by comparing different wayfinding designs and show that our optimized wayfinding design can guide pedestrians to their destinations effectively and efficiently. Our approach can also help the designer visualize the accessibility of a destination from different locations, and correct any “blind zone” with additional signs.</p>  </div>  <div class="div-h1">    <h1>Bibtex</h1>  </div>  <div class="div-project-cell">    <p class="list">@article{wayfinding,</br>      &nbsp;author = {Haikun Huang and Ni-Ching Lin and Lorenzo Barrett and Darian Springer and Hsueh-Cheng Wang and Marc Pomplun and Lap-Fai Yu},</br>      &nbsp;title = {Automatic Optimization of Wayfinding Design},</br>      &nbsp;journal = {IEEE Transactions on Visualization and Computer Graphics},</br>      &nbsp;year = {2017}</br>      } </p>  </div>  <div class="div-h1">    <h1>Acknowledgments</h1>  </div>  <div class="div-project-cell">    <p class="list">We thank Ana Aravena for narrating the demonstration video. </p>    </br>    <p class="list"><em>This research is supported by the UMass Boston StartUp Grant P20150000029280 and by the Joseph P. Healey Research Grant Program provided by the Office of the Vice Provost for Research and Strategic Initiatives &amp; Dean of Graduate Studies of UMass Boston. </em></p>    <p class="list"><em>This research is also supported by the National Science Foundation under award number 1565978. We acknowledge NVIDIA Corporation for graphics card donation.</em></p>  </div>  <!-- InstanceEndEditable --> </main>
<!--	<hr>-->
<footer>
  <div class="footer">Copyright 2020 © Haikun (Quincy) Huang</div>
</footer>
</body>
<!-- InstanceEnd --></html>

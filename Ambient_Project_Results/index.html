<p><!doctype html>
<html>
<head>
<meta charset="utf-8">
<title>Ambient dataset</title>
</head>

<body>
<h1>Audible Panorama:Automatic Spatial Audio Generation for Panorama Imagery</h1>
	<p>
		<a href="../ambient.html">Project Page</a> 
	</p>
<h3>Examples of object detection.</h3>
Given a panorama image, our system will run the object detection on the slices sampled from the panorama image.<br>
The objects in the slices will be marked by a bounding box with the confidence score.<br>
Click on a thumbnail to see the full image in a new tag.<br>
<br>
<table width="880" border="0" align="l">
  <tbody>
    <tr align="center">
      <th scope="col">ID</th>
      <th scope="col">Scene</th>
      <th scope="col">Samples</th>
    </tr>
    <tr align="center">
      <td width="10">1</td>
      <td width="200"><a target="_blank" href="panorama/Chinatown.JPG"><img src="panorama/Chinatown.JPG" width="200" height="100" alt=""/></a></td>
      <td width="580"><a target="_blank" href="data\Chinatown\scene\0_0_0_visualized.jpg"><img src="data\Chinatown\scene\0_0_0_visualized.jpg" width="200" height="100" alt=""/></a> <a target="_blank" href="data\Chinatown\scene\0_72_0_visualized.jpg"><img src="data\Chinatown\scene\0_72_0_visualized.jpg" width="200" height="100" alt=""/></a> <a target="_blank" href="data\Chinatown\scene\0_216_0_visualized.jpg"><img src="data\Chinatown\scene\0_216_0_visualized.jpg" width="200" height="100" alt=""/></a></td>
    </tr>
    <tr align="center">
      <td>2</td>
      <td><a target="_blank" href="panorama/SchoolCafe.JPG"><img src="panorama/SchoolCafe.JPG" width="200" height="100" alt=""/></a></td>
      <td><a target="_blank" href="data\Cafeteria\scene\0_0_0_visualized.jpg"><img src="data\Cafeteria\scene\0_0_0_visualized.jpg" width="200" height="100" alt=""/></a> <a target="_blank" href="data\Cafeteria\scene\0_72_0_visualized.jpg"><img src="data\Cafeteria\scene\0_72_0_visualized.jpg" width="200" height="100" alt=""/></a> <a target="_blank" href="data\Cafeteria\scene\0_216_0_visualized.jpg"><img src="data\Cafeteria\scene\0_216_0_visualized.jpg" width="200" height="100" alt=""/></a></td>
    </tr>
    <tr align="center">
      <td> 3</td>
      <td><a target="_blank" href="panorama/shoppingmall_ssp.JPG"><img src="panorama/shoppingmall_ssp.JPG" width="200" height="100" alt=""/></a></td>
      <td><a target="_blank" href="data\Shoppingmall\scene\0_0_0_visualized.jpg"><img src="data\Shoppingmall\scene\0_0_0_visualized.jpg" width="200" height="100" alt=""/></a> <a target="_blank" href="data\Shoppingmall\scene\0_72_0_visualized.jpg"><img src="data\Shoppingmall\scene\0_72_0_visualized.jpg" width="200" height="100" alt=""/></a> <a target="_blank" href="data\Shoppingmall\scene\0_216_0_visualized.jpg"><img src="data\Shoppingmall\scene\0_216_0_visualized.jpg" width="200" height="100" alt=""/></a></td>
    </tr>
    <tr>
      <td>... </td>
      <td>1300 plus scenes.</td>
      <td>Please download the results to obtain all examples.</td>
    </tr>
  </tbody>
</table>
<h3>Download the <a href="https://www.dropbox.com/s/3yw90xo9r5bp0i7/results.zip?dl=0">results</a> and the <a href="https://www.dropbox.com/s/4btc85omtlhcorj/soundDatabase.zip?dl=0">sound database</a>. </h3>
<h5>***NOTE: We run our approach on 1305 images, but due to the copyright issues, we only provide the URL to download the images instead of putting the images on our website ***</h5>

<h3>Results:</h3>
The <strong>results</strong> file includes 2 folders:
<ul>
  <strong>panorama:</strong> includes all the panorama images we captured by ourselves and the file <b>downloadLinks.txt</b> contains the download links to the Flickr images.
</ul>
<ul>
  <strong>data:</strong> includes all the raw data and the result data which is generated by our system for each scene.
</ul>
<br>	
In the <strong>data</strong> folder, each sub-folder is associated with a panorama image in the <strong>panorama</strong> folder.
<ul>
  <strong>scene:</strong> includes the visualization of the object detection for the slices of the panorama image.
</ul>
<ul>
  <B>data.ini:</B> the raw data of scene classification, object detection, and object recognition.
</ul>
<ul>
  <B>fullSound.ini:</B> the result data generated by our system.
</ul>
<br>
<h3>Format of downloadLinks.txt:</h3>
For each line, we have: <br>
<ul>Image name,</ul>
<ul>License type,</ul>
<ul>The Image exactly download URL,</ul>
<ul>The original webpage which the image has been posted.</ul>
<strong>Example:</strong> ZZZ25086550514, license:1, https://farm2.staticflickr.com/1629/25086550514_240a1a97c4_o.jpg, https://www.flickr.com/photos/24128368@N00/25086550514/ <br>
<br>
<strong>License type:</strong> <br>
<ul><strong>0</strong>: <a href="">All Rights Reserved</a></ul>
<ul><strong>1</strong>: <a href="https://creativecommons.org/licenses/by-nc-sa/2.0/">Attribution-NonCommercial-ShareAlike License</a></ul>
<ul><strong>2</strong>: <a href="https://creativecommons.org/licenses/by-nc/2.0/">Attribution-NonCommercial License</a></ul>
<ul><strong>3</strong>: <a href="https://creativecommons.org/licenses/by-nc-nd/2.0/">Attribution-NonCommercial-NoDerivs License</a></ul>
<ul><strong>4</strong>: <a href="https://creativecommons.org/licenses/by/2.0/">Attribution License</a></ul>
<ul><strong>5</strong>: <a href="https://creativecommons.org/licenses/by-sa/2.0/">Attribution-ShareAlike License</a></ul>
<ul><strong>6</strong>: <a href="https://creativecommons.org/licenses/by-nd/2.0/">Attribution-NoDerivs License</a></ul>
<ul><strong>7</strong>: <a href="https://www.flickr.com/commons/usage/">No known copyright restrictions</a></ul>
<ul><strong>8</strong>: <a href="http://www.usa.gov/copyright.shtml">United States Government Work</a></ul>
<ul><strong>9</strong>: <a href="https://creativecommons.org/publicdomain/zero/1.0/">Public Domain Dedication (CC0)</a></ul>
<ul><strong>10</strong>: <a href="https://creativecommons.org/publicdomain/mark/1.0/">Public Domain Mark</a></ul>
	
	
<br>	
<h3>Format of data.ini:</h3>
The data.ini file contains the raw data of scene classification, object detection, and object recognition.<br>
<br>
We use the <strong>section-key-value-comment</strong> pair to organize this file.<br>
The format of the pair is: <strong>[section] key = value ; comment</strong>.<br>
*** Note: anything after the semicolon ";" will be the comment and the comment would not provide any useful information.***<br>
<h4>Base Section:</h4>
The <strong>Base</strong> section provides a overall information about the scene classification, the object detection and the object recognition.
<ul>
  <strong>frameCount</strong>: indicates how many slices for the panorama image, it always be 10.
</ul>
<ul>
  <strong>objectCount</strong>: indicates the how many objects in total. It includes the duplicated objects, we will remove them later.
</ul>
<ul>
  <strong>objectCatalogCount</strong>: indicates how many object catalogs have been detected in this scene.
</ul>
<ul>
  <strong>objectCatalogList</strong>: shows the list of object catalogs.
</ul>
<ul>
  <strong>sortedDescription</strong>: shows the list of scene catalogs sorted by their scores.
</ul>
<ul>
  <strong>sortedScore</strong>: shows the list of scores of the scene catalogs.
</ul>
<ul>
  <strong>unDuplicatedObjectIds</strong>: the ids of the unduplicated objects.
</ul>
<ul>
  <strong>unDuplicatedObjectIdsCount</strong>: the # of the unduplicated objects.
</ul>
<h4>Frame Section:</h4>
The format of the <strong>Frame</strong> section is [frame_X] where X is the id of the frame.
<ul>
  <strong>cameraEulerAngle</strong>: the euler angle of the camera while shooting this frame.
</ul>
<ul>
  <strong>imageWidth & imageHeight</strong>: the size of the frame.
</ul>
<ul>
  <strong>file</strong>: the path if of screenshot of the frame.
</ul>
<ul>
  <strong>objList</strong>: the list of the object's ids detected from this frame. (Includes the duplicated objects.)
</ul>
<ul>
  <strong>objCount</strong>: the # of objects. (Includes the duplicated objects.)
</ul>
<ul>
  <strong>description</strong>: the list of the scene classification of the frame.
</ul>
<ul>
  <strong>score</strong>: the list of scores associate with the description.
</ul>
<h4>Object Section:</h4>
The format of the <strong>Object</strong> section is [Object_X] where X is the id of the object.
<ul>
  <strong>frame</strong>: indicats which frame the object belongs to.
</ul>
<ul>
  <strong>tag</strong>: the tag of this object.
</ul>
<ul>
  <strong>minY,minX,maxY,maxX</strong>: the frame of the bounding box.
</ul>
<ul>
  <strong>center,leftTop,leftBottom,rightTop,rightBottom</strong>: the angles in euler of this object. The angle of the center can be turned into the direction of the object related to the orign of the virtual world.
</ul>
<ul>
  <strong>depth</strong>: the depth of the object base on the reference object.
</ul>
<ul>
  <strong>action</strong>: the action tag detected by the object recognition. Only the unduplicated person object will have this key.
</ul>
<br>
<br>
<h3>Format of fullsounds.ini:</h3>
The fullsounds.ini file is generated by our system base on our approach. <br>
The system will use this file to place the sounds to the scene.<br>
<br>
We use the <strong>section-key-value-comment</strong> pair to organize this file.<br>
The format of the pair is: <strong>[section] key = value ; comment</strong>.<br>
*** Note: anything after the semicolon ";" will be the comment and the comment would not provide any useful information.***<br>
<br>
<h4>Base Section:</h4>
The <strong>Base</strong> section provides a overall information about the scene classification, the object detection and the object recognition.
<ul>
  <strong>soundCount</strong>: the # of objects in this scene.
</ul>
<h4>Sound Section:</h4>
The format of the <strong>Sound</strong> section is [Sound_X] where X is the id of the sound.
<ul>
  <strong>tag</strong>: the tag of this sound.
</ul>
<ul>
  <strong>soundFile</strong>: the sound file the system used.
</ul>
<ul>
  <strong>bObject</strong>: indicates if this sound is an object or background. <strong>True</strong> means object and <strong>False</strong> means background.
</ul>
<ul>
  <strong>location</strong>: the location of this sound.
</ul>
<br>
<br>
<h3>Sound Database:</h3>
The <strong>soundDatabase</strong> file includes 2 folders: <strong>background</strong> and <strong>soundableObject</strong>.<br>
The sub-folders of these two folders are named based on the tags for scene classification and object recognition. <br>
The mp3 files in those sub-folders are the sound sources we used in our system.
</body>

</html>
</p>
<!doctype html>
<html><!-- InstanceBegin template="/Templates/GeneralPage.dwt" codeOutsideHTMLIsLocked="false" --> 
<head>
<meta charset="UTF-8" >
<!-- InstanceBeginEditable name="doctitle" -->
<title>Haikun Huang</title>
<!-- InstanceEndEditable -->
<!-- InstanceBeginEditable name="head" -->
<link href="style.css" rel="stylesheet" type="text/css">
<!-- InstanceEndEditable -->

<!--The following script tag downloads a font from the Adobe Edge Web Fonts server for use within the web page. We recommend that you do not modify it.-->
<script>var __adobewebfontsappname__="dreamweaver"</script>
<script src="http://use.edgefonts.net/bilbo:n4:default.js" type="text/javascript"></script>
</head>

<body>
<header>
  <div class="titlename"><strong>Haikun (Quincy) Huang</strong></div>
  <div class="body-header-div">
	  <a href="index.html" class="nav">Home</a>&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="publications.html" class="nav">Publications</a>&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="about.html" class="nav">Team</a>&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href ="./CV/Haikun_cv_one_page.pdf" class="nav" target="new">CV</a>&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://scholar.google.com/citations?view_op=search_authors&mauthors=Haikun+Huang&hl=en&oi=ao" class="nav" target="new">Google Scholar</a></div>
</header>
<main> <!-- InstanceBeginEditable name="EditRegion Main" --> 
  
	 <!-- Gallery -->
  <div>
    <table border="0">
      <tbody>
        <tr>
          <td><img src="thumbnails/gallery.png" width="200"  alt=""/></td>
          <!-- title -->
          <td valign="top"><strong><em>Interactive Design of Gallery Walls via Mixed Reality</em></strong><br>
            
            <!-- authors --> 
            <strong>Haikun Huang</strong>,Yuxuan Zhang, Tomer Weiss, Rebecca W Perry, Lap-Fai Yu, Lap-Fai Yu<br>
            
            <!-- summary --> 
            a novel interactive design tool that allows users to create and visualize gallery walls via a mixed reality device.<br>
            
            <!-- keys --> 
            <a class="keyword">Design Interfaces | Mixed Reality | Spatial Computing</a> <br>
            
            <!-- venue --> 
            <a class="venue">IEEE AIVR, 2020</a> <br>
            
            <!-- links --> 
            <a href="gallery.html" target="new">Project Page</a> | <a href="" target="new">Paper</a> | <a href="https://www.youtube.com/watch?v=RH7wHCpW1SI" target="new">Video</a> | <a href="bibtex.txt" target="new">Bibtex</a></td>
        </tr>
      </tbody>
    </table>
  </div>
  <br>
	
  <!-- Exertion-Aware Path Generation -->
  <div>
    <table border="0">
      <tbody>
        <tr>
          <td><img src="thumbnails/level3.png" width="200"  alt=""/></td>
          <!-- title -->
          <td valign="top"><strong><em>Exertion-Aware Path Generation</em></strong><br>
            
            <!-- authors --> 
            *Wanwan Li, *Biao Xie, Yongqi Zhang, Walter Meiss, <strong>Haikun Huang</strong>, Lap-Fai Yu<br>
            *Equal contributors<br>
            
            <!-- summary --> 
            Generating exertion-aware paths over 3D terrains for VR exercising.<br>
            
            <!-- keys --> 
            <a class="keyword">Procedural Modeling | Level Design | Path Generation | Haptics</a> <br>
            
            <!-- venue --> 
            <a class="venue">ACM Transactions on Graphics (Proceeding of <strong>SIGGRAPH 2020</strong>)</a> <br>
            
            <!-- links --> 
            <a href="https://craigyuyu.github.io/home/project_pages/exertion/exertion.html" target="new">Project Page</a> | <a href="paper/level3_low.pdf" target="new">Paper</a> | <a href="https://www.youtube.com/watch?v=0SGnlEWescU" target="new">Video</a> | <a href="bibtex.txt" target="new">Bibtex</a></td>
        </tr>
      </tbody>
    </table>
  </div>
  <br>
	
  <!-- Audible Panorama: Automatic Spatial Audio Generation for Panorama Imagery -->
  <div>
    <table border="0">
      <tbody>
        <tr>
          <td><img src="thumbnails/ambient_optimized.gif" width="200"  alt=""/></td>
          <!-- title -->
          <td valign="top"><strong><em>Audible Panorama:
            Automatic Spatial Audio Generation for Panorama Imagery</em></strong><br>
            
            <!-- authors --> 
            <strong>*Haikun Huang</strong>, *Michael S. Solah, Dingzeyu Li, Lap-Fai Yu<br>
            *Equal contributors<br>
            
            <!-- summary --> 
            This work automatically synthesizes realistic spatial sounds for 360° panorama images for delivering immersive VR experiences.<br>
            
            <!-- keys --> 
            <a class="keyword">Immersive Media | Spatial Audio | Panorama Images | Virtual Reality | Augmented Reality</a> <br>
            
            <!-- venue --> 
            <a class="venue">Proceedings of the ACM Conference on Human Factors in Computing Systems (<strong>CHI 2019</strong>)</a> <br>
            
            <!-- links --> 
            <a href="./ambient.html" target="new">Project Page</a> | <a href="paper/Ambient_LowRes.pdf" target="new">Paper</a> | <a href="https://youtu.be/W9MHHZiIjxU" target="new">Video</a> | <a href="bibtex.txt" target="new">Bibtex</a></td>
        </tr>
      </tbody>
    </table>
  </div>
	<br>
	
	<!-- Gaze-driven Adaptive Aid for VR Navigation -->
  <div>
    <table border="0">
      <tbody>
        <tr>
          <td><img src="thumbnails/vr_lost_optimized.gif" width="200"  alt=""/></td>
          <!-- title -->
          <td valign="top"><strong><em>Gaze-driven Adaptive Aid for VR Navigation</em></strong><br>
            
            <!-- authors --> 
            Rawan Alghofaili, Yasuhito Sawahata, <strong>Haikun Huang</strong>, Hsueh-Cheng Wang, Takaaki Shiratori, Lap-Fai Yu<br>
            
            <!-- summary --> 
            Feel lost when navigating in a virtual environment (such as when playing a VR game)? This tool helps you get back on track by predicting when you need navigation help and popping up wayfinding aids.<br>
            
            <!-- keys --> 
            <a class="keyword">Games/Play | Virtual/Augmented Reality | Eye Tracking</a> <br>
            
            <!-- venue --> 
            <a class="venue">Proceedings of the ACM Conference on Human Factors in Computing Systems (<strong>CHI 2019</strong>)</a> <br>
            
            <!-- links --> 
            <a href="https://rawanmg.github.io/research/lost" target="new">Project Page</a> | <a href="paper/vrlost.pdf" target="new">Paper</a> | <a href="https://youtu.be/s6Vw2eie8F4" target="new">Video</a> | <a href="bibtex.txt" target="new">Bibtex</a></td>
        </tr>
      </tbody>
    </table>
  </div>
	<br>
	<!-- Optimizing Visual Element Placement via Visual Attention Analysis -->
  <div>
    <table border="0">
      <tbody>
        <tr>
          <td><img src="thumbnails/vreye.png" width="200"  alt=""/></td>
          <!-- title -->
          <td valign="top"><strong><em>Optimizing Visual Element Placement via Visual Attention Analysis</em></strong><br>
            
            <!-- authors --> 
            Rawan Alghofaili, Michael Solah, <strong>Haikun Huang</strong>, Yasuhito Sawahata, Marc Pomplun, Lap-Fai Yu<br>
            
            <!-- summary --> 
            Populating visual elements (e.g., ads) in 3D virtual environments based on a visual attention predictor trained by eye-gaze data.<br>
            
            <!-- keys --> 
            <a class="keyword">Computing Methodologies—Computer Graphics—Graphics systems | Interfaces—Virtual Reality</a> <br>
            
            <!-- venue --> 
            <a class="venue"><strong>IEEE Virtual Reality (VR 2019)</strong></a> <br>
            
            <!-- links --> 
            <a href="https://rawanmg.github.io/research/vr19.html" target="new">Project Page</a> | <a href="paper/vr19.pdf" target="new">Paper</a> | <a href="https://youtu.be/G442b8DBU6Y" target="new">Video</a> | <a href="bibtex.txt" target="new">Bibtex</a></td>
        </tr>
      </tbody>
    </table>
  </div>
	<br>
	
	<!-- Pose-Guided Level Design -->
  <div>
    <table border="0">
      <tbody>
        <tr>
          <td><img src="thumbnails/level2_optimized.gif" width="200"  alt=""/></td>
          <!-- title -->
          <td valign="top"><strong><em>Pose-Guided Level Design</em></strong><br>
            
            <!-- authors --> 
            *Yongqi Zhang, *Biao Xie, <strong>Haikun Huang</strong>, Elisa Ogawa, Tongjian You, Lap-Fai Yu<br>
            *Equal contributors<br>
            
            <!-- summary --> 
            Procedural game level generator for motion/exercise games (e.g., Just Dance, Speed of Light).<br>
            
            <!-- keys --> 
            <a class="keyword">Level Design | Optimization | Exergaming | Generative Designv</a> <br>
            
            <!-- venue --> 
            <a class="venue">Proceedings of the ACM Conference on Human Factors in Computing Systems (<strong>CHI 2019</strong>)</a> <br>
			  
			  <!-- Award -->
			<a href="https://chi2019.acm.org/2019/03/15/chi-2019-best-papers-honourable-mentions/" target="new">CHI 2019 Honourable Mentions Award</a><br>
            
            <!-- links --> 
            <a href="http://blogs.umb.edu/yongqizhang001/pose-guided-level-design/" target="new">Project Page</a> | <a href="paper/level2.pdf" target="new">Paper</a> | <a href="https://www.youtube.com/watch?v=uRqwKZWw6Fo&feature=youtu.be" target="new">Video</a> | <a href="bibtex.txt" target="new">Bibtex</a></td>
        </tr>
      </tbody>
    </table>
  </div>
	<br>
	
	<!-- Exercise Intensity-driven Level Design -->
  <div>
    <table border="0">
      <tbody>
        <tr>
          <td><img src="thumbnails/exergame.gif" width="200"  alt=""/></td>
          <!-- title -->
          <td valign="top"><strong><em>Exercise Intensity-driven Level Design</em></strong><br>
            
            <!-- authors --> 
            Biao Xie*, Yongqi Zhang*, <strong>Haikun Huang</strong>, Elisa Ogawa, Tongjian You, Lap-Fai Yu<br>
            *Equal contributors<br>
            
            <!-- summary --> 
            This work automatically synthesizes realistic spatial sounds for 360° panorama images for delivering immersive VR experiences.<br>
            
            <!-- keys --> 
            <a class="keyword">Level Design | Optimization | Exergaming | Generative Design</a> <br>
            
            <!-- venue --> 
            <a class="venue">IEEE Transactions on Visualization and Computer Graphics (TVCG), 2018 (<strong>Special Issue on IEEE Virtual Reality 2018</strong>)</a> <br>
			<a class="venue">In IEEE Transactions on Visualization and Computer Graphics, vol. 24, no. 4, pp. 1661-1670, April 2018.doi: 10.1109/TVCG.2018.2793618 (Special Issue on IEEE Virtual Reality 2018. Acceptance Rate: 15%)</a> <br>
			  
			  <!-- Award -->
			<a href="https://innovate.ieee.org/innovation-spotlight/vr-games-exercise-intensity-level-design-plug-in/" target="new">Featured on IEEE Xplore Innovation Spotlight</a><br>
            
            <!-- links --> 
            <a href="https://biaoxie.github.io/home/projects/level1/level1.html" target="new">Project Page</a> | <a href="paper/level.pdf" target="new">Paper</a> | <a href="https://www.youtube.com/watch?v=I2JvVL1dW3s" target="new">Video</a> | <a href="bibtex.txt" target="new">Bibtex</a></td>
        </tr>
      </tbody>
    </table>
  </div>
	<br>

<!-- Deep Trail-Following Robotic Guide Dog in Pedestrian Environments for People who are Blind and Visually Impaired - Learning from Virtual and Real Worlds -->
  <div>
    <table border="0">
      <tbody>
        <tr>
          <td><img src="thumbnails/guidedog.png" width="200"  alt=""/></td>
          <!-- title -->
          <td valign="top"><strong><em>Deep Trail-Following Robotic Guide Dog in Pedestrian Environments for People who are Blind and Visually Impaired - Learning from Virtual and Real Worlds</em></strong><br>
            
            <!-- authors --> 
            Tzu-Kuan Chuang, Ni-Ching Lin, Jih-Shi Chen, Chen-Hao Hung, Yi-Wei Huang, Chunchih Teng, <strong>Haikun Huang</strong>, Lap-Fai Yu, Laura Giarre, Hsueh-Cheng Wang<br>
            
            <!-- summary --> 
            Training a robotic guidedog that can help blind people to navigate in the real world.<br>
            
            
            <!-- venue --> 
            <a class="venue">IEEE International Conference on Robotics and Automation (<strong>ICRA 2018</strong>)</a> <br>
			  
            
            <!-- links --> 
            <a href="paper/guidedog.pdf" target="new">Paper</a> | <a href="https://vimeo.com/257645104" target="new">Video</a> | <a href="bibtex.txt" target="new">Bibtex</a></td>
        </tr>
      </tbody>
    </table>
  </div>
	<br>
	
	<!-- Automatic Optimization of Wayfinding Design -->
  <div>
    <table border="0">
      <tbody>
        <tr>
          <td><img src="thumbnails/wayfinding.png" width="200"  alt=""/></td>
          <!-- title -->
          <td valign="top"><strong><em>Automatic Optimization of Wayfinding Design</em></strong><br>
            
            <!-- authors --> 
            <strong>Haikun Huang</strong>, Ni-Ching Lin, Lorenzo Barrett, Darian Springer, Hsueh-Cheng Wang, Marc Pomplun, Lap-Fai Yu<br>
            
            <!-- summary --> 
            An automatic tool to help wayfinding designers create better wayfinding designs for architectural spaces, and to help level designers create better game levels.<br>
            
            <!-- keys --> 
            <a class="keyword">Wayfinding | Navigation | Procedural Modeling | Level Design | Spatial Orientation</a> <br>
            
            <!-- venue --> 
            <a class="venue">IEEE Transactions on Visualization and Computer Graphics (<strong>TVCG 2017</strong>)</a> <br>
			  

            
            <!-- links --> 
            <a href="wayfinding.html" target="new">Project Page</a> | <a href="paper/wayfinding_main.pdf" target="new">Paper</a> | <a href="https://youtu.be/gKWTial7cKg" target="new">Video</a> | <a href="bibtex.txt" target="new">Bibtex</a></td>
        </tr>
      </tbody>
    </table>
  </div>
	<br>

	<!-- Analyzing Visual Attention via Virtual Environments -->
  <div>
    <table border="0">
      <tbody>
        <tr>
          <td><img src="thumbnails/vrpr.png" width="200"  alt=""/></td>
          <!-- title -->
          <td valign="top"><strong><em>Analyzing Visual Attention via Virtual Environments</em></strong><br>
            
            <!-- authors --> 
            <strong>Haikun Huang</strong>, Ni-Ching Lin, Lorenzo Barrett, Darian Springer, Hsueh-Cheng Wang, Marc Pomplun, Lap-Fai Yu<br>
            
            <!-- keys --> 
            <a class="keyword">VR | Training</a> <br>
            
            <!-- venue --> 
            <a class="venue"><strong>Virtual Reality meets Physical Reality Workshop, SIGGRAPH Asia, 2016</strong></a> <br>
            
            <!-- links --> 
          	<a href="paper/vrAttention.pdf" target="new">Paper</a> | <a href="bibtex.txt" target="new">Bibtex</a></td>
        </tr>
      </tbody>
    </table>
  </div>
	<br>
	
	<!-- Physiological Responses and Enjoyment of Kinect-Based Exergames in Older Adults at Risk for Falls: A Feasibility Study -->
  <div>
    <table border="0">
      <tbody>
        <tr>
          <td width="200"></td>
          <!-- title -->
          <td valign="top"><strong><em>Physiological Responses and Enjoyment of Kinect-Based Exergames in Older Adults at Risk for Falls: A Feasibility Study</em></strong><br>
            
            <!-- authors --> 
            Ogawa EF, <strong>Huang Haikun</strong>, Yu Lap-Fai, Gona GN, Fleming RK, Leveille SG, You T<br>
           
            
            <!-- keys --> 
            <a class="keyword">Exergaming | Dual-Task | Older Adults</a> <br>
            
            <!-- venue --> 
            <a class="venue">Manuscript under review at Medicine and Science in Sports and Exercise</a> <br>
			  
            
            <!-- links --> 
            <a href="bibtex.txt" target="new">Bibtex</a></td>
        </tr>
      </tbody>
    </table>
  </div>
	<br>
	
	<!-- Effects of Exergaming on Cognition and Dual-Task Mobility in Older Adults at Risk for Falling -->
  <div>
    <table border="0">
      <tbody>
        <tr>
          <td width="200"></td>
          <!-- title -->
          <td valign="top"><strong><em>Effects of Exergaming on Cognition and Dual-Task Mobility in Older Adults at Risk for Falling</em></strong><br>
            
            <!-- authors --> 
            Ogawa EF, <strong>Huang Haikun</strong>, Yu Lap-Fai, Gona GN, Fleming RK, Leveille SG, You T<br>
           
            
            <!-- keys --> 
            <a class="keyword">Exergaming | Dual-Task | Older Adults</a> <br>
            
            <!-- venue --> 
            <a class="venue">Manuscript under review at Medicine and Science in Sports and Exercise</a> <br>
			  
            
            <!-- links --> 
            <a href="bibtex.txt" target="new">Bibtex</a></td>
        </tr>
      </tbody>
    </table>
  </div>
	<br>

	

	
	
  <!-- InstanceEndEditable --> </main>
<!--	<hr>-->
<footer>
  <div class="footer">Copyright 2020 © Haikun (Quincy) Huang</div>
</footer>
</body>
<!-- InstanceEnd --></html>
